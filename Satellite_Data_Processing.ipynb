{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Satellite Data Processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anoopmanikantas/Time-Series-analysis-of-Satellite-data-Feature-extractions-on-Transitions/blob/main/Satellite_Data_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oD_9KjBsnwe"
      },
      "source": [
        "Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_Na-fgZsmmd",
        "cellView": "form"
      },
      "source": [
        "#@title Imports\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import tifffile as tiff\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import backend as K\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import math\n",
        "import gc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE9QxXCdBXcz",
        "cellView": "form"
      },
      "source": [
        "#@title Seed = 123456\n",
        "np.random.seed(123456)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R02uhY0BDf3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "4ede4c9c-31eb-430b-a813-deb570313dcf"
      },
      "source": [
        "#@title Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDYI17Z53WO8"
      },
      "source": [
        "Copying data from drive to colab local storage for faster access during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJkQzk2G2mUc",
        "cellView": "form"
      },
      "source": [
        "#@title Create data dir in colab storage\n",
        "!mkdir /content/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcF2B24j3KFi",
        "cellView": "form"
      },
      "source": [
        "#@title Copy contents from drive to the data dir\n",
        "!cp -r /content/drive/MyDrive/data/* /content/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46mymCy2st6T"
      },
      "source": [
        "#@title Constants\n",
        "MAIN_DIR = '/content/data/'\n",
        "N_BANDS = 8\n",
        "N_CLASSES = 5  # buildings, roads, trees, crops and water\n",
        "CLASS_WEIGHTS = [0.2, 0.3, 0.1, 0.1, 0.3]\n",
        "N_EPOCHS = 150\n",
        "UPCONV = True\n",
        "PATCH_SZ = 16\n",
        "BATCH_SIZE = 100\n",
        "STRIDE = 1\n",
        "MODEL_NAME = \"/unet_weights.hdf5\"\n",
        "TRAIN_SZ = 0.75\n",
        "TEST_IMAGE = 'test'\n",
        "TEST_IMAGE1 = '22'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJBriZAICAKF"
      },
      "source": [
        "Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GODi-sIjKp5a",
        "cellView": "form"
      },
      "source": [
        "#@title Function to visualize a 16 bit image (by converting to 8 bit)\n",
        "def stretch_8bit(bands, lower_percent=2, higher_percent=98):\n",
        "    out = np.zeros_like(bands)\n",
        "    for i in range(3):\n",
        "        a = 0 \n",
        "        b = 255 \n",
        "        c = np.percentile(bands[:,:,i], lower_percent)\n",
        "        d = np.percentile(bands[:,:,i], higher_percent)        \n",
        "        t = a + (bands[:,:,i] - c) * (b - a) / (d - c)    \n",
        "        t[t<a] = a\n",
        "        t[t>b] = b\n",
        "        out[:,:,i] =t\n",
        "    return out.astype(np.uint8)    \n",
        "def visualize(filename):\n",
        "    img = tiff.imread(filename)\n",
        "    img = np.rollaxis(img, 0, 3)\n",
        "    img1 = np.zeros((img.shape[0],img.shape[1],3))\n",
        "    img1[:,:,0] = img[:,:,4] #red\n",
        "    img1[:,:,1] = img[:,:,2] #green\n",
        "    img1[:,:,2] = img[:,:,1] #blue\n",
        "    return stretch_8bit(img1)\n",
        "# img = visualize(input_raster)\n",
        "# plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvRKshEHbPl2",
        "cellView": "form"
      },
      "source": [
        "#@title Visualization (uncomment to see the results)\n",
        "# fig,ax = plt.subplots(24,6,figsize=(50,200))\n",
        "# masks = ['Buildings', 'Roads', 'Trees', 'Crops', 'Water']\n",
        "# ax[0][0].set_title('maps', fontsize=25)\n",
        "# for mask in range(5):\n",
        "#     ax[0][mask+1].set_title(masks[mask], fontsize=25)\n",
        "# for img_id in range(24):\n",
        "#   input_raster = MAIN_DIR+'mband/{}.tif'.format(str(img_id+1).zfill(2))\n",
        "#   mask_raster = MAIN_DIR+'gt_mband/{}.tif'.format(str(img_id+1).zfill(2))\n",
        "#   img_8_bit = visualize(input_raster)\n",
        "#   img_mask = tiff.imread(mask_raster)\n",
        "#   ax[img_id][0].imshow(img_8_bit, interpolation='nearest', aspect='auto')\n",
        "#   ax[img_id][0].axes.xaxis.set_visible(False)\n",
        "#   ax[img_id][0].axes.yaxis.set_visible(False)  \n",
        "#   for mask in range(5):\n",
        "#     ax[img_id][mask+1].imshow(img_mask[mask], interpolation='nearest', aspect='auto')\n",
        "#     ax[img_id][mask+1].axes.xaxis.set_visible(False)\n",
        "#     ax[img_id][mask+1].axes.yaxis.set_visible(False)\n",
        "# plt.subplots_adjust(hspace=0.05,wspace=0.05)\n",
        "# plt.savefig('map_viz.png')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDfjFhcsWk8a"
      },
      "source": [
        "Training begins here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPkp9fyXKkOz",
        "cellView": "form"
      },
      "source": [
        "#@title Normalize the input\n",
        "def normalize(img):\n",
        "    min = img.min()\n",
        "    max = img.max()\n",
        "    x = 2.0 * (img - min) / (max - min) - 1.0\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LsaPbCsbwN3"
      },
      "source": [
        "U-Net model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soSXbHkebvN6"
      },
      "source": [
        "#@title Unet-model\n",
        "def unet_model(n_classes=5, im_sz=160, n_channels=8, n_filters_start=32, growth_factor=2, upconv=True,\n",
        "               class_weights=[0.2, 0.3, 0.1, 0.1, 0.3]):\n",
        "    droprate=0.25\n",
        "    n_filters = n_filters_start\n",
        "    inputs = Input((im_sz, im_sz, n_channels))\n",
        "    #inputs = BatchNormalization()(inputs)\n",
        "    conv1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    #pool1 = Dropout(droprate)(pool1)\n",
        "\n",
        "    n_filters *= growth_factor\n",
        "    pool1 = BatchNormalization()(pool1)\n",
        "    conv2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    pool2 = Dropout(droprate)(pool2)\n",
        "\n",
        "    n_filters *= growth_factor\n",
        "    pool2 = BatchNormalization()(pool2)\n",
        "    conv3 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    pool3 = Dropout(droprate)(pool3)\n",
        "\n",
        "    n_filters *= growth_factor\n",
        "    pool3 = BatchNormalization()(pool3)\n",
        "    conv4_0 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4_0 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv4_0)\n",
        "    pool4_1 = MaxPooling2D(pool_size=(2, 2))(conv4_0)\n",
        "    pool4_1 = Dropout(droprate)(pool4_1)\n",
        "\n",
        "    n_filters *= growth_factor\n",
        "    pool4_1 = BatchNormalization()(pool4_1)\n",
        "    conv4_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool4_1)\n",
        "    conv4_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv4_1)\n",
        "    pool4_2 = MaxPooling2D(pool_size=(2, 2))(conv4_1)\n",
        "    pool4_2 = Dropout(droprate)(pool4_2)\n",
        "\n",
        "    n_filters *= growth_factor\n",
        "    conv5 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool4_2)\n",
        "    conv5 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up6_1 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv5), conv4_1])\n",
        "    else:\n",
        "        up6_1 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4_1])\n",
        "    up6_1 = BatchNormalization()(up6_1)\n",
        "    conv6_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up6_1)\n",
        "    conv6_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv6_1)\n",
        "    conv6_1 = Dropout(droprate)(conv6_1)\n",
        "\n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up6_2 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv6_1), conv4_0])\n",
        "    else:\n",
        "        up6_2 = concatenate([UpSampling2D(size=(2, 2))(conv6_1), conv4_0])\n",
        "    up6_2 = BatchNormalization()(up6_2)\n",
        "    conv6_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up6_2)\n",
        "    conv6_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv6_2)\n",
        "    conv6_2 = Dropout(droprate)(conv6_2)\n",
        "\n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up7 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv6_2), conv3])\n",
        "    else:\n",
        "        up7 = concatenate([UpSampling2D(size=(2, 2))(conv6_2), conv3])\n",
        "    up7 = BatchNormalization()(up7)\n",
        "    conv7 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv7)\n",
        "    conv7 = Dropout(droprate)(conv7)\n",
        "\n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up8 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv7), conv2])\n",
        "    else:\n",
        "        up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2])\n",
        "    up8 = BatchNormalization()(up8)\n",
        "    conv8 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up8)\n",
        "    conv8 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv8)\n",
        "    conv8 = Dropout(droprate)(conv8)\n",
        "\n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up9 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv8), conv1])\n",
        "    else:\n",
        "        up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1])\n",
        "    conv9 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up9)\n",
        "    conv9 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "    conv10 = Conv2D(n_classes, (1, 1), activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=conv10)\n",
        "    # def soft_dice_loss(y_true, y_pred, epsilon=1e-6): \n",
        "    #     axes = tuple(range(1, len(y_pred.shape)-1)) \n",
        "    #     numerator = 2. * K.sum(y_pred * y_true, axes)\n",
        "    #     denominator = K.sum(K.square(y_pred) + K.square(y_true), axes)\n",
        "    #     return 1 - K.mean((numerator + epsilon) / (denominator + epsilon))\n",
        "    def weighted_binary_crossentropy(y_true, y_pred):\n",
        "        class_loglosses = K.mean(K.binary_crossentropy(y_true, y_pred), axis=[0, 1, 2])\n",
        "        return K.sum(class_loglosses * K.constant(class_weights))\n",
        "        \n",
        "    model.compile(optimizer=Adam(), loss=weighted_binary_crossentropy)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L22_HIE0_YhV",
        "cellView": "form"
      },
      "source": [
        "#@title function to get memory usage by the model\n",
        "def get_model_memory_usage(batch_size, model):\n",
        "    import numpy as np\n",
        "    try:\n",
        "        from keras import backend as K\n",
        "    except:\n",
        "        from tensorflow.keras import backend as K\n",
        "\n",
        "    shapes_mem_count = 0\n",
        "    internal_model_mem_count = 0\n",
        "    for l in model.layers:\n",
        "        layer_type = l.__class__.__name__\n",
        "        if layer_type == 'Model':\n",
        "            internal_model_mem_count += get_model_memory_usage(batch_size, l)\n",
        "        single_layer_mem = 1\n",
        "        out_shape = l.output_shape\n",
        "        if type(out_shape) is list:\n",
        "            out_shape = out_shape[0]\n",
        "        for s in out_shape:\n",
        "            if s is None:\n",
        "                continue\n",
        "            single_layer_mem *= s\n",
        "        shapes_mem_count += single_layer_mem\n",
        "\n",
        "    trainable_count = np.sum([K.count_params(p) for p in model.trainable_weights])\n",
        "    non_trainable_count = np.sum([K.count_params(p) for p in model.non_trainable_weights])\n",
        "\n",
        "    number_size = 4.0\n",
        "    if K.floatx() == 'float16':\n",
        "        number_size = 2.0\n",
        "    if K.floatx() == 'float64':\n",
        "        number_size = 8.0\n",
        "\n",
        "    total_memory = number_size * (batch_size * shapes_mem_count + trainable_count + non_trainable_count)\n",
        "    gbytes = np.round(total_memory / (1024.0 ** 3), 3) + internal_model_mem_count\n",
        "    return gbytes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PnnLolOuiCi",
        "cellView": "form"
      },
      "source": [
        "#@title print model memory usage (uncomment to see the results)\n",
        "\n",
        "# model = get_model()\n",
        "# print(get_model_memory_usage(BATCH_SIZE,model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G32c4GlwrabT",
        "cellView": "form"
      },
      "source": [
        "#@title Data Generator\n",
        "class DataGenerator(Sequence):\n",
        "    \"\"\"Generates data for Keras\n",
        "    Sequence based data generator. Suitable for building data generator for training and prediction.\n",
        "    \"\"\"\n",
        "    def __init__(self, list_IDs, labels,to_fit=True, batch_size=BATCH_SIZE, dim=(PATCH_SZ, PATCH_SZ),\n",
        "                 n_channels=N_BANDS, n_classes=N_CLASSES, shuffle=True):\n",
        "        \"\"\"Initialization\n",
        "\n",
        "        :param list_IDs: list of all 'label' ids to use in the generator\n",
        "        :param labels: list of image labels (file names)\n",
        "        :param image_path: path to images location\n",
        "        :param mask_path: path to masks location\n",
        "        :param to_fit: True to return X and y, False to return X only\n",
        "        :param batch_size: batch size at each iteration\n",
        "        :param dim: tuple indicating image dimension\n",
        "        :param n_channels: number of image channels\n",
        "        :param n_classes: number of output masks\n",
        "        :param shuffle: True to shuffle label indexes after every epoch\n",
        "        \"\"\"\n",
        "        self.list_IDs = list_IDs\n",
        "        self.labels = labels\n",
        "        self.to_fit = to_fit\n",
        "        self.batch_size = batch_size\n",
        "        self.dim = dim\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Denotes the number of batches per epoch\n",
        "\n",
        "        :return: number of batches per epoch\n",
        "        \"\"\"\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Generate one batch of data\n",
        "\n",
        "        :param index: index of the batch\n",
        "        :return: X and y when fitting. X only when predicting\n",
        "        \"\"\"\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "        # Generate data\n",
        "        \n",
        "        X = self._generate_X(list_IDs_temp)\n",
        "        if self.to_fit:\n",
        "          y = self._generate_y(list_IDs_temp)\n",
        "          return X, y\n",
        "        return X\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\n",
        "\n",
        "        \"\"\"\n",
        "        gc.collect()\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def _generate_X(self, list_IDs_temp):\n",
        "        \"\"\"Generates data containing batch_size images\n",
        "\n",
        "        :param list_IDs_temp: list of label ids to load\n",
        "        :return: batch of images\n",
        "        \"\"\"\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        for i,ind in enumerate(list_IDs_temp):\n",
        "          img_id,x,y = self.labels[ind]\n",
        "          X[i,] = TRAIN_IMG_RAW[img_id][x:(x+PATCH_SZ),y:(y+PATCH_SZ)] \n",
        "        return X\n",
        "    def _generate_y(self, list_IDs_temp):\n",
        "        \"\"\"Generates data containing batch_size masks\n",
        "\n",
        "        :param list_IDs_temp: list of label ids to load\n",
        "        :return: batch if masks\n",
        "        \"\"\"\n",
        "        Y = np.empty((self.batch_size, *self.dim, self.n_classes))\n",
        "        for i,ind in enumerate(list_IDs_temp):\n",
        "          img_id,x,y = self.labels[ind]\n",
        "          Y[i,] = TRAIN_IMG_MASK_RAW[img_id][x:(x+PATCH_SZ),y:(y+PATCH_SZ)] \n",
        "        return Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XolI2SDucLoc"
      },
      "source": [
        "Creating weights directory and storing all the images and masks in memory to avoid reloading all the time inside the datagenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcbbJd0vZQYe",
        "cellView": "form"
      },
      "source": [
        "#@title Create weights path\n",
        "weights_path = 'weights'\n",
        "if not os.path.exists(weights_path):\n",
        "    os.makedirs(weights_path)\n",
        "weights_path += MODEL_NAME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYN0WgWAd4S8"
      },
      "source": [
        "Loading the training and validation data..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klJdRHC1cjpr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "4c979631-ca56-48b2-eab8-b9e6ebae3040"
      },
      "source": [
        "#@title Store image and mask in memory\n",
        "TRAIN_IMG_RAW = []\n",
        "TRAIN_IMG_MASK_RAW = []\n",
        "for img_id in tqdm(range(1,25)):\n",
        "  img = normalize(tiff.imread(MAIN_DIR+'mband/{}.tif'.format(str(img_id).zfill(2)))).transpose([1,2,0])\n",
        "  mask = tiff.imread(MAIN_DIR+'gt_mband/{}.tif'.format(str(img_id).zfill(2))).transpose([1,2,0])/255\n",
        "  TRAIN_IMG_RAW.append(img)\n",
        "  TRAIN_IMG_MASK_RAW.append(mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [00:01<00:00, 15.31it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN3RpZIefqA8"
      },
      "source": [
        "Patch generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXlq4o0RpYKW",
        "cellView": "form"
      },
      "source": [
        "#@title function to generate the compressed form of the dataset (Version 1)\n",
        "# def get_label(stride = 1,patch_size = PATCH_SZ):\n",
        "#   labels = dict()\n",
        "#   idx = 0\n",
        "#   for i in range(1,25):\n",
        "#     img_id = str(i).zfill(2)+'.tif'\n",
        "#     img = MAIN_DIR+\"mband/\"+img_id\n",
        "#     img = tiff.imread(img).transpose([1,2,0]).shape\n",
        "#     w,h = img[0],img[1]\n",
        "#     for j in range(0,w-patch_size+1,stride):\n",
        "#       for k in range(0,h-patch_size+1,stride):\n",
        "#         labels[idx] = (i-1,j,k)\n",
        "#         idx+=1\n",
        "#   return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "9GvvG3q6YXB5"
      },
      "source": [
        "#@title function to generate the compressed form of the dataset (Version 2)\n",
        "def get_label(stride=1,patch_size=PATCH_SZ):\n",
        "  train_labels = dict()\n",
        "  val_labels = dict()\n",
        "  idx = 0\n",
        "  for i in range(1,25):\n",
        "    labels = dict()\n",
        "    img_id = str(i).zfill(2)+'.tif'\n",
        "    img = MAIN_DIR+\"mband/\"+img_id\n",
        "    img = tiff.imread(img).transpose([1,2,0]).shape\n",
        "    w,h = img[0],img[1]\n",
        "    for j in range(0,w-patch_size+1,stride):\n",
        "      for k in range(0,h-patch_size+1,stride):\n",
        "        labels[idx] = (i-1,j,k)\n",
        "        idx+=1\n",
        "    labels = list(labels.items())\n",
        "    # print(labels)\n",
        "    np.random.shuffle(labels)\n",
        "    labels_len = len(labels)\n",
        "    train_labels.update({key:value for key,value in labels[:int((3/4)*labels_len)]})\n",
        "    val_labels.update({key:value for key,value in labels[int((3/4)*labels_len):]})\n",
        "    del labels\n",
        "  return train_labels,val_labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tFY2tILva-g"
      },
      "source": [
        "Generating Labels "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW9u-lEavaYW",
        "cellView": "form"
      },
      "source": [
        "#@title Generate the compressed form of the dataset (version 1)\n",
        "# labels = get_label(stride=STRIDE)\n",
        "# print(\"Dataset size =\",len(labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "thOcfGXybCLN",
        "outputId": "caac053a-5b65-4447-f8ba-b7575a7c651c"
      },
      "source": [
        "#@title Generate the compressed form of the dataset (version 2)\n",
        "train_labels,val_labels = get_label(stride=STRIDE)\n",
        "print(\"Dataset size =\",len(train_labels)+len(val_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset size = 12788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKxYPWCsv9-s"
      },
      "source": [
        "Create data generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1y8j2uZv_5R",
        "cellView": "form"
      },
      "source": [
        "#@title Split the dataset into train and validation (version 1)\n",
        "# dataset_size = len(labels)\n",
        "# indexes = [*range(dataset_size)]\n",
        "# np.random.shuffle(indexes)\n",
        "# train_idx = indexes[:int(TRAIN_SZ*dataset_size)]\n",
        "# val_idx = indexes[int(TRAIN_SZ*dataset_size):]\n",
        "# training_generator = DataGenerator(train_idx,labels)\n",
        "# validation_generator = DataGenerator(val_idx,labels)\n",
        "# print(\"TRAIN size =\",len(train_idx),\"Validation size =\",len(val_idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "Pxoch8UbbMZM",
        "outputId": "b42eb864-30c1-49da-da72-c01bb94dd291"
      },
      "source": [
        "#@title Split the dataset into train and validation (version 2)\n",
        "train_idx = list(train_labels.keys())\n",
        "val_idx = list(val_labels.keys())\n",
        "training_generator = DataGenerator(train_idx,train_labels)\n",
        "validation_generator = DataGenerator(val_idx,val_labels)\n",
        "print(\"TRAIN size =\",len(train_idx),\"Validation size =\",len(val_idx))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN size = 9576 Validation size = 3212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRkarBCNgbPV"
      },
      "source": [
        "Let's train!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaOUxe1DjFha",
        "cellView": "form"
      },
      "source": [
        "#@title function to get the model\n",
        "def get_model():\n",
        "    return unet_model(N_CLASSES, PATCH_SZ, n_channels=N_BANDS, upconv=UPCONV, class_weights=CLASS_WEIGHTS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahUprRSQfLpm"
      },
      "source": [
        "#@title function to train the neural net\n",
        "def train_net():\n",
        "  model = get_model()\n",
        "  if os.path.isfile(weights_path):\n",
        "      model.load_weights(weights_path)\n",
        "  #model_checkpoint = ModelCheckpoint(weights_path, monitor='val_loss', save_weights_only=True, save_best_only=True)\n",
        "  #early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "  #reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5, min_lr=0.00001)\n",
        "  # model_checkpoint = ModelCheckpoint('weights/unet_weights--{epoch:02d}-{val_loss:.4f}.hdf5', monitor='val_loss', save_best_only=True)\n",
        "  model_checkpoint = ModelCheckpoint('weights/unet_weights.hdf5', monitor='val_loss', save_best_only=True)\n",
        "  csv_logger = CSVLogger('log_unet.csv', append=True, separator=';')\n",
        "  tensorboard = TensorBoard(log_dir='./tensorboard_unet/', write_graph=True, write_images=True)\n",
        "  model.fit(training_generator, epochs=N_EPOCHS,\n",
        "            verbose=1,callbacks=[model_checkpoint, csv_logger, tensorboard],\n",
        "            validation_data=validation_generator)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDKhoLfjguVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be5cb958-51c3-429c-afcd-cc7510dfb419"
      },
      "source": [
        "#@title Start training\n",
        "train_net()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "159/159 [==============================] - 223s 1s/step - loss: 0.1495 - val_loss: 0.3909\n",
            "Epoch 2/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.1027 - val_loss: 0.3237\n",
            "Epoch 3/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0873 - val_loss: 0.1136\n",
            "Epoch 4/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0800 - val_loss: 0.1386\n",
            "Epoch 5/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0744 - val_loss: 0.0742\n",
            "Epoch 6/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0707 - val_loss: 0.0736\n",
            "Epoch 7/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0683 - val_loss: 0.0900\n",
            "Epoch 8/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0657 - val_loss: 0.0693\n",
            "Epoch 9/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0619 - val_loss: 0.0600\n",
            "Epoch 10/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0607 - val_loss: 0.0786\n",
            "Epoch 11/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0588 - val_loss: 0.0587\n",
            "Epoch 12/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0564 - val_loss: 0.0555\n",
            "Epoch 13/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0551 - val_loss: 0.0595\n",
            "Epoch 14/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0547 - val_loss: 0.0515\n",
            "Epoch 15/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0524 - val_loss: 0.0546\n",
            "Epoch 16/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0513 - val_loss: 0.0530\n",
            "Epoch 17/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0513 - val_loss: 0.0529\n",
            "Epoch 18/150\n",
            "159/159 [==============================] - 182s 1s/step - loss: 0.0482 - val_loss: 0.0578\n",
            "Epoch 19/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0474 - val_loss: 0.0466\n",
            "Epoch 20/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0457 - val_loss: 0.0584\n",
            "Epoch 21/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0441 - val_loss: 0.0453\n",
            "Epoch 22/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0434 - val_loss: 0.0454\n",
            "Epoch 23/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0421 - val_loss: 0.0510\n",
            "Epoch 24/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0415 - val_loss: 0.0434\n",
            "Epoch 25/150\n",
            "159/159 [==============================] - 182s 1s/step - loss: 0.0397 - val_loss: 0.0392\n",
            "Epoch 26/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0387 - val_loss: 0.0365\n",
            "Epoch 27/150\n",
            "159/159 [==============================] - 182s 1s/step - loss: 0.0372 - val_loss: 0.0364\n",
            "Epoch 28/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0370 - val_loss: 0.0373\n",
            "Epoch 29/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0356 - val_loss: 0.0332\n",
            "Epoch 30/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0346 - val_loss: 0.0343\n",
            "Epoch 31/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0533 - val_loss: 0.0516\n",
            "Epoch 32/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0397 - val_loss: 0.0464\n",
            "Epoch 33/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0357 - val_loss: 0.0329\n",
            "Epoch 34/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0348 - val_loss: 0.0318\n",
            "Epoch 35/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0331 - val_loss: 0.0319\n",
            "Epoch 36/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0321 - val_loss: 0.0296\n",
            "Epoch 37/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0317 - val_loss: 0.0292\n",
            "Epoch 38/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0313 - val_loss: 0.0369\n",
            "Epoch 39/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0326 - val_loss: 0.0284\n",
            "Epoch 40/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0303 - val_loss: 0.0280\n",
            "Epoch 41/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0300 - val_loss: 0.0279\n",
            "Epoch 42/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0290 - val_loss: 0.0266\n",
            "Epoch 43/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0287 - val_loss: 0.0274\n",
            "Epoch 44/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0282 - val_loss: 0.0305\n",
            "Epoch 45/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0451 - val_loss: 0.0540\n",
            "Epoch 46/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0307 - val_loss: 0.0305\n",
            "Epoch 47/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0286 - val_loss: 0.0278\n",
            "Epoch 48/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0275 - val_loss: 0.0263\n",
            "Epoch 49/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0289 - val_loss: 0.0452\n",
            "Epoch 50/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0279 - val_loss: 0.0255\n",
            "Epoch 51/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0267 - val_loss: 0.0246\n",
            "Epoch 52/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0264 - val_loss: 0.0238\n",
            "Epoch 53/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0261 - val_loss: 0.0239\n",
            "Epoch 54/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0261 - val_loss: 0.0247\n",
            "Epoch 55/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0253 - val_loss: 0.0233\n",
            "Epoch 56/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0250 - val_loss: 0.0261\n",
            "Epoch 57/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0247 - val_loss: 0.0223\n",
            "Epoch 58/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0245 - val_loss: 0.0247\n",
            "Epoch 59/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0264 - val_loss: 0.0573\n",
            "Epoch 60/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0257 - val_loss: 0.0228\n",
            "Epoch 61/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0243 - val_loss: 0.0236\n",
            "Epoch 62/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0237 - val_loss: 0.0217\n",
            "Epoch 63/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0235 - val_loss: 0.0218\n",
            "Epoch 64/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0234 - val_loss: 0.0212\n",
            "Epoch 65/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0228 - val_loss: 0.0206\n",
            "Epoch 66/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0230 - val_loss: 0.0214\n",
            "Epoch 67/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0226 - val_loss: 0.0220\n",
            "Epoch 68/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0226 - val_loss: 0.0206\n",
            "Epoch 69/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0226 - val_loss: 0.0207\n",
            "Epoch 70/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0221 - val_loss: 0.0209\n",
            "Epoch 71/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0322 - val_loss: 0.0240\n",
            "Epoch 72/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0226 - val_loss: 0.0208\n",
            "Epoch 73/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0220 - val_loss: 0.0200\n",
            "Epoch 74/150\n",
            "159/159 [==============================] - 178s 1s/step - loss: 0.0216 - val_loss: 0.0197\n",
            "Epoch 75/150\n",
            "138/159 [=========================>....] - ETA: 21s - loss: 0.0288"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLvZ9swegvkc"
      },
      "source": [
        "#@title Load the test image and the model\n",
        "model = get_model()\n",
        "model.load_weights(weights_path)\n",
        "img = normalize(tiff.imread(MAIN_DIR+'mband/{}.tif'.format(TEST_IMAGE)).transpose([1,2,0]))   # make channels last"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOmzbT-x0xFe"
      },
      "source": [
        "#@title Function to predict on the given test image\n",
        "def predict(x, model, patch_sz=160, n_classes=5):\n",
        "    img_height = x.shape[0]\n",
        "    img_width = x.shape[1]\n",
        "    n_channels = x.shape[2]\n",
        "    # make extended img so that it contains integer number of patches\n",
        "    npatches_vertical = math.ceil(img_height / patch_sz)\n",
        "    npatches_horizontal = math.ceil(img_width / patch_sz)\n",
        "    extended_height = patch_sz * npatches_vertical\n",
        "    extended_width = patch_sz * npatches_horizontal\n",
        "    ext_x = np.zeros(shape=(extended_height, extended_width, n_channels), dtype=np.float32)\n",
        "    # fill extended image with mirrors:\n",
        "    ext_x[:img_height, :img_width, :] = x\n",
        "    for i in range(img_height, extended_height):\n",
        "        ext_x[i, :, :] = ext_x[2 * img_height - i - 1, :, :]\n",
        "    for j in range(img_width, extended_width):\n",
        "        ext_x[:, j, :] = ext_x[:, 2 * img_width - j - 1, :]\n",
        "\n",
        "    # now we assemble all patches in one array\n",
        "    patches_list = []\n",
        "    for i in range(0, npatches_vertical):\n",
        "        for j in range(0, npatches_horizontal):\n",
        "            x0, x1 = i * patch_sz, (i + 1) * patch_sz\n",
        "            y0, y1 = j * patch_sz, (j + 1) * patch_sz\n",
        "            patches_list.append(ext_x[x0:x1, y0:y1, :])\n",
        "    # model.predict() needs numpy array rather than a list\n",
        "    patches_array = np.asarray(patches_list)\n",
        "    # predictions:\n",
        "    patches_predict = model.predict(patches_array, batch_size=4)\n",
        "    prediction = np.zeros(shape=(extended_height, extended_width, n_classes), dtype=np.float32)\n",
        "    for k in range(patches_predict.shape[0]):\n",
        "        i = k // npatches_horizontal\n",
        "        j = k % npatches_vertical\n",
        "        x0, x1 = i * patch_sz, (i + 1) * patch_sz\n",
        "        y0, y1 = j * patch_sz, (j + 1) * patch_sz\n",
        "        prediction[x0:x1, y0:y1, :] = patches_predict[k, :, :, :]\n",
        "    return prediction[:img_height, :img_width, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4KgquB21CXf"
      },
      "source": [
        "#@title Perform prediction\n",
        "prediction = predict(img,model,patch_sz=PATCH_SZ).transpose([2,0,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsFV3M841IHj",
        "cellView": "form"
      },
      "source": [
        "#@title function to generate picture given mask\n",
        "def picture_from_mask(mask, threshold=0):\n",
        "    colors = {\n",
        "        0: [150, 150, 150],  # Buildings\n",
        "        1: [223, 194, 125],  # Roads & Tracks\n",
        "        2: [27, 120, 55],    # Trees\n",
        "        3: [166, 219, 160],  # Crops\n",
        "        4: [116, 173, 209]   # Water\n",
        "    }\n",
        "    z_order = {\n",
        "        1: 3,\n",
        "        2: 4,\n",
        "        3: 0,\n",
        "        4: 1,\n",
        "        5: 2\n",
        "    }\n",
        "    pict = 255*np.ones(shape=(3, mask.shape[1], mask.shape[2]), dtype=np.uint8)\n",
        "    for i in range(1,6):\n",
        "        cl = z_order[i]\n",
        "        for ch in range(3):\n",
        "            pict[ch,:,:][mask[cl,:,:] > threshold] = colors[cl][ch]\n",
        "    return pict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0HNEVgC1lhz"
      },
      "source": [
        "#@title Generate picture form mask\n",
        "land_map = picture_from_mask(prediction,0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6apR80ha3-kx"
      },
      "source": [
        "#@title Preprocess original test image\n",
        "img1_8_bit = visualize(MAIN_DIR+'mband/{}.tif'.format(TEST_IMAGE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36AF1_6LhD-k"
      },
      "source": [
        "#@title Display prediction and original\n",
        "fig, ax = plt.subplots(1,2,figsize=(15,8))\n",
        "ax[0].imshow(land_map.transpose([1,2,0]), interpolation='nearest', aspect='auto')\n",
        "ax[1].imshow(img1_8_bit, interpolation='nearest', aspect='auto')\n",
        "ax[0].axes.xaxis.set_visible(False)\n",
        "ax[0].axes.yaxis.set_visible(False)\n",
        "ax[1].axes.xaxis.set_visible(False)\n",
        "ax[1].axes.yaxis.set_visible(False)\n",
        "ax[0].set_title(\"Predicted map\",fontsize=15)\n",
        "ax[1].set_title(\"Original map\",fontsize=15)\n",
        "plt.subplots_adjust(hspace=0.05,wspace=0.05)\n",
        "plt.savefig('result.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Oxmf-U8EtcS"
      },
      "source": [
        "#@title Prediction on a trained image\n",
        "img1 = normalize(tiff.imread(MAIN_DIR+'mband/{}.tif'.format(TEST_IMAGE1)).transpose([1,2,0]))\n",
        "prediction = predict(img1,model,patch_sz=PATCH_SZ).transpose([2,0,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qSiglUzEyIT"
      },
      "source": [
        "#@title Display prediction on trained image\n",
        "gt_img = tiff.imread(MAIN_DIR+'gt_mband/{}.tif'.format(TEST_IMAGE1))/255\n",
        "land_map1 = picture_from_mask(prediction,0.5)\n",
        "gt_land_map = picture_from_mask(gt_img,0.5)\n",
        "img2_8_bit = visualize(MAIN_DIR+'mband/{}.tif'.format(TEST_IMAGE1))\n",
        "fig, ax = plt.subplots(1,3,figsize=(20,8))\n",
        "ax[0].imshow(land_map1.transpose([1,2,0]), interpolation='nearest', aspect='auto')\n",
        "ax[1].imshow(gt_land_map.transpose([1,2,0]), interpolation='nearest', aspect='auto')\n",
        "ax[2].imshow(img2_8_bit, interpolation='nearest', aspect='auto')\n",
        "ax[0].axes.xaxis.set_visible(False)\n",
        "ax[0].axes.yaxis.set_visible(False)\n",
        "ax[1].axes.xaxis.set_visible(False)\n",
        "ax[1].axes.yaxis.set_visible(False)\n",
        "ax[2].axes.xaxis.set_visible(False)\n",
        "ax[2].axes.yaxis.set_visible(False)\n",
        "ax[0].set_title(\"Predicted map\",fontsize=15)\n",
        "ax[1].set_title(\"Ground truth map\",fontsize=15)\n",
        "ax[2].set_title(\"Original map\",fontsize=15)\n",
        "plt.subplots_adjust(hspace=0.05,wspace=0.05)\n",
        "plt.savefig('result1.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}