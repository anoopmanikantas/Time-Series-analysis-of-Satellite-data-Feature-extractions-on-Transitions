{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Satellite_Data_Processing_Local_runtime.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anoopmanikantas/Time-Series-analysis-of-Satellite-data-Feature-extractions-on-Transitions/blob/main/Satellite_Data_Processing_Local_runtime.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZg0fwsrCJkj"
      },
      "source": [
        "This notebook is to connect colab UI to local runtime jupyter backend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oD_9KjBsnwe"
      },
      "source": [
        "Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_Na-fgZsmmd",
        "cellView": "form"
      },
      "source": [
        "#@title Imports\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import tifffile as tiff\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import backend as K\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import math\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "kE9QxXCdBXcz"
      },
      "source": [
        "#@title Seed = 0\n",
        "np.random.seed(0)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDYI17Z53WO8"
      },
      "source": [
        "Copying data from drive to colab local storage for faster access during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46mymCy2st6T",
        "cellView": "form"
      },
      "source": [
        "#@title Constants\n",
        "MAIN_DIR = './data/'\n",
        "N_BANDS = 8\n",
        "N_CLASSES = 5  # buildings, roads, trees, crops and water\n",
        "CLASS_WEIGHTS = [0.2, 0.3, 0.1, 0.1, 0.3]\n",
        "N_EPOCHS = 20\n",
        "UPCONV = True\n",
        "PATCH_SZ = 160\n",
        "BATCH_SIZE = 10\n",
        "STRIDE = 8\n",
        "MODEL_NAME = \"/unet_weights.hdf5\"\n",
        "TRAIN_SZ = 0.75\n",
        "TEST_IMAGE = '22'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJBriZAICAKF"
      },
      "source": [
        "Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GODi-sIjKp5a",
        "cellView": "form"
      },
      "source": [
        "#@title Function to visualize a 16 bit image (by converting to 8 bit)\n",
        "def stretch_8bit(bands, lower_percent=2, higher_percent=98):\n",
        "    out = np.zeros_like(bands)\n",
        "    for i in range(3):\n",
        "        a = 0 \n",
        "        b = 255 \n",
        "        c = np.percentile(bands[:,:,i], lower_percent)\n",
        "        d = np.percentile(bands[:,:,i], higher_percent)        \n",
        "        t = a + (bands[:,:,i] - c) * (b - a) / (d - c)    \n",
        "        t[t<a] = a\n",
        "        t[t>b] = b\n",
        "        out[:,:,i] =t\n",
        "    return out.astype(np.uint8)    \n",
        "def visualize(filename):\n",
        "    img = tiff.imread(filename)\n",
        "    img = np.rollaxis(img, 0, 3)\n",
        "    img1 = np.zeros((img.shape[0],img.shape[1],3))\n",
        "    img1[:,:,0] = img[:,:,4] #red\n",
        "    img1[:,:,1] = img[:,:,2] #green\n",
        "    img1[:,:,2] = img[:,:,1] #blue\n",
        "    return stretch_8bit(img1)\n",
        "# img = visualize(input_raster)\n",
        "# plt.imshow(img)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvRKshEHbPl2",
        "cellView": "form"
      },
      "source": [
        "#@title Visualization (uncomment to see the results)\n",
        "# fig,ax = plt.subplots(24,6,figsize=(50,200))\n",
        "# masks = ['Buildings', 'Roads', 'Trees', 'Crops', 'Water']\n",
        "# ax[0][0].set_title('maps', fontsize=25)\n",
        "# for mask in range(5):\n",
        "#     ax[0][mask+1].set_title(masks[mask], fontsize=25)\n",
        "# for img_id in range(24):\n",
        "#   input_raster = MAIN_DIR+'mband/{}.tif'.format(str(img_id+1).zfill(2))\n",
        "#   mask_raster = MAIN_DIR+'gt_mband/{}.tif'.format(str(img_id+1).zfill(2))\n",
        "#   img_8_bit = visualize(input_raster)\n",
        "#   img_mask = tiff.imread(mask_raster)\n",
        "#   ax[img_id][0].imshow(img_8_bit, interpolation='nearest', aspect='auto')\n",
        "#   ax[img_id][0].axes.xaxis.set_visible(False)\n",
        "#   ax[img_id][0].axes.yaxis.set_visible(False)  \n",
        "#   for mask in range(5):\n",
        "#     ax[img_id][mask+1].imshow(img_mask[mask], interpolation='nearest', aspect='auto')\n",
        "#     ax[img_id][mask+1].axes.xaxis.set_visible(False)\n",
        "#     ax[img_id][mask+1].axes.yaxis.set_visible(False)\n",
        "# plt.subplots_adjust(hspace=0.05,wspace=0.05)\n",
        "# plt.savefig('map_viz.png')\n",
        "# plt.show()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDfjFhcsWk8a"
      },
      "source": [
        "Training begins here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPkp9fyXKkOz",
        "cellView": "form"
      },
      "source": [
        "#@title Normalize the input\n",
        "def normalize(img):\n",
        "    min = img.min()\n",
        "    max = img.max()\n",
        "    x = 2.0 * (img - min) / (max - min) - 1.0\n",
        "    return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LsaPbCsbwN3"
      },
      "source": [
        "U-Net model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soSXbHkebvN6",
        "cellView": "form"
      },
      "source": [
        "#@title Unet-model\n",
        "def unet_model(n_classes=5, im_sz=160, n_channels=8, n_filters_start=32, growth_factor=2, upconv=True,\n",
        "               class_weights=[0.2, 0.3, 0.1, 0.1, 0.3]):\n",
        "    droprate=0.25\n",
        "    n_filters = n_filters_start\n",
        "    inputs = Input((im_sz, im_sz, n_channels))\n",
        "    #inputs = BatchNormalization()(inputs)\n",
        "    conv1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    #pool1 = Dropout(droprate)(pool1)\n",
        "\n",
        "    n_filters *= growth_factor\n",
        "    pool1 = BatchNormalization()(pool1)\n",
        "    conv2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    pool2 = Dropout(droprate)(pool2)\n",
        "\n",
        "    n_filters *= growth_factor\n",
        "    pool2 = BatchNormalization()(pool2)\n",
        "    conv3 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    pool3 = Dropout(droprate)(pool3)\n",
        "\n",
        "    n_filters *= growth_factor\n",
        "    pool3 = BatchNormalization()(pool3)\n",
        "    conv4_0 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4_0 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv4_0)\n",
        "    pool4_1 = MaxPooling2D(pool_size=(2, 2))(conv4_0)\n",
        "    pool4_1 = Dropout(droprate)(pool4_1)\n",
        "\n",
        "    n_filters *= growth_factor\n",
        "    pool4_1 = BatchNormalization()(pool4_1)\n",
        "    conv4_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool4_1)\n",
        "    conv4_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv4_1)\n",
        "    pool4_2 = MaxPooling2D(pool_size=(2, 2))(conv4_1)\n",
        "    pool4_2 = Dropout(droprate)(pool4_2)\n",
        "\n",
        "    n_filters *= growth_factor\n",
        "    conv5 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool4_2)\n",
        "    conv5 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up6_1 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv5), conv4_1])\n",
        "    else:\n",
        "        up6_1 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4_1])\n",
        "    up6_1 = BatchNormalization()(up6_1)\n",
        "    conv6_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up6_1)\n",
        "    conv6_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv6_1)\n",
        "    conv6_1 = Dropout(droprate)(conv6_1)\n",
        "\n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up6_2 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv6_1), conv4_0])\n",
        "    else:\n",
        "        up6_2 = concatenate([UpSampling2D(size=(2, 2))(conv6_1), conv4_0])\n",
        "    up6_2 = BatchNormalization()(up6_2)\n",
        "    conv6_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up6_2)\n",
        "    conv6_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv6_2)\n",
        "    conv6_2 = Dropout(droprate)(conv6_2)\n",
        "\n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up7 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv6_2), conv3])\n",
        "    else:\n",
        "        up7 = concatenate([UpSampling2D(size=(2, 2))(conv6_2), conv3])\n",
        "    up7 = BatchNormalization()(up7)\n",
        "    conv7 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv7)\n",
        "    conv7 = Dropout(droprate)(conv7)\n",
        "\n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up8 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv7), conv2])\n",
        "    else:\n",
        "        up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2])\n",
        "    up8 = BatchNormalization()(up8)\n",
        "    conv8 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up8)\n",
        "    conv8 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv8)\n",
        "    conv8 = Dropout(droprate)(conv8)\n",
        "\n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up9 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv8), conv1])\n",
        "    else:\n",
        "        up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1])\n",
        "    conv9 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up9)\n",
        "    conv9 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "    conv10 = Conv2D(n_classes, (1, 1), activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "    def weighted_binary_crossentropy(y_true, y_pred):\n",
        "        class_loglosses = K.mean(K.binary_crossentropy(y_true, y_pred), axis=[0, 1, 2])\n",
        "        return K.sum(class_loglosses * K.constant(class_weights))\n",
        "        \n",
        "    model.compile(optimizer=Adam(), loss=weighted_binary_crossentropy)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L22_HIE0_YhV",
        "cellView": "form"
      },
      "source": [
        "#@title function to get memory usage by the model\n",
        "def get_model_memory_usage(batch_size, model):\n",
        "    import numpy as np\n",
        "    try:\n",
        "        from keras import backend as K\n",
        "    except:\n",
        "        from tensorflow.keras import backend as K\n",
        "\n",
        "    shapes_mem_count = 0\n",
        "    internal_model_mem_count = 0\n",
        "    for l in model.layers:\n",
        "        layer_type = l.__class__.__name__\n",
        "        if layer_type == 'Model':\n",
        "            internal_model_mem_count += get_model_memory_usage(batch_size, l)\n",
        "        single_layer_mem = 1\n",
        "        out_shape = l.output_shape\n",
        "        if type(out_shape) is list:\n",
        "            out_shape = out_shape[0]\n",
        "        for s in out_shape:\n",
        "            if s is None:\n",
        "                continue\n",
        "            single_layer_mem *= s\n",
        "        shapes_mem_count += single_layer_mem\n",
        "\n",
        "    trainable_count = np.sum([K.count_params(p) for p in model.trainable_weights])\n",
        "    non_trainable_count = np.sum([K.count_params(p) for p in model.non_trainable_weights])\n",
        "\n",
        "    number_size = 4.0\n",
        "    if K.floatx() == 'float16':\n",
        "        number_size = 2.0\n",
        "    if K.floatx() == 'float64':\n",
        "        number_size = 8.0\n",
        "\n",
        "    total_memory = number_size * (batch_size * shapes_mem_count + trainable_count + non_trainable_count)\n",
        "    gbytes = np.round(total_memory / (1024.0 ** 3), 3) + internal_model_mem_count\n",
        "    return gbytes"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PnnLolOuiCi",
        "cellView": "form"
      },
      "source": [
        "#@title print model memory usage (uncomment to see the results)\n",
        "\n",
        "# model = get_model()\n",
        "# print(get_model_memory_usage(BATCH_SIZE,model))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G32c4GlwrabT",
        "cellView": "form"
      },
      "source": [
        "#@title Data Generator\n",
        "class DataGenerator(Sequence):\n",
        "    \"\"\"Generates data for Keras\n",
        "    Sequence based data generator. Suitable for building data generator for training and prediction.\n",
        "    \"\"\"\n",
        "    def __init__(self, list_IDs, labels,to_fit=True, batch_size=BATCH_SIZE, dim=(PATCH_SZ, PATCH_SZ),\n",
        "                 n_channels=N_BANDS, n_classes=N_CLASSES, shuffle=True):\n",
        "        \"\"\"Initialization\n",
        "\n",
        "        :param list_IDs: list of all 'label' ids to use in the generator\n",
        "        :param labels: list of image labels (file names)\n",
        "        :param image_path: path to images location\n",
        "        :param mask_path: path to masks location\n",
        "        :param to_fit: True to return X and y, False to return X only\n",
        "        :param batch_size: batch size at each iteration\n",
        "        :param dim: tuple indicating image dimension\n",
        "        :param n_channels: number of image channels\n",
        "        :param n_classes: number of output masks\n",
        "        :param shuffle: True to shuffle label indexes after every epoch\n",
        "        \"\"\"\n",
        "        self.list_IDs = list_IDs\n",
        "        self.labels = labels\n",
        "        self.to_fit = to_fit\n",
        "        self.batch_size = batch_size\n",
        "        self.dim = dim\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Denotes the number of batches per epoch\n",
        "\n",
        "        :return: number of batches per epoch\n",
        "        \"\"\"\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Generate one batch of data\n",
        "\n",
        "        :param index: index of the batch\n",
        "        :return: X and y when fitting. X only when predicting\n",
        "        \"\"\"\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "        # Generate data\n",
        "        \n",
        "        X = self._generate_X(list_IDs_temp)\n",
        "        if self.to_fit:\n",
        "          y = self._generate_y(list_IDs_temp)\n",
        "          return X, y\n",
        "        return X\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\n",
        "\n",
        "        \"\"\"\n",
        "        gc.collect()\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def _generate_X(self, list_IDs_temp):\n",
        "        \"\"\"Generates data containing batch_size images\n",
        "\n",
        "        :param list_IDs_temp: list of label ids to load\n",
        "        :return: batch of images\n",
        "        \"\"\"\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        for i,ind in enumerate(list_IDs_temp):\n",
        "          img_id,x,y = labels[ind]\n",
        "          X[i,] = TRAIN_IMG_RAW[img_id][x:(x+PATCH_SZ),y:(y+PATCH_SZ)] \n",
        "        return X\n",
        "    def _generate_y(self, list_IDs_temp):\n",
        "        \"\"\"Generates data containing batch_size masks\n",
        "\n",
        "        :param list_IDs_temp: list of label ids to load\n",
        "        :return: batch if masks\n",
        "        \"\"\"\n",
        "        Y = np.empty((self.batch_size, *self.dim, self.n_classes))\n",
        "        for i,ind in enumerate(list_IDs_temp):\n",
        "          img_id,x,y = labels[ind]\n",
        "          Y[i,] = TRAIN_IMG_MASK_RAW[img_id][x:(x+PATCH_SZ),y:(y+PATCH_SZ)] \n",
        "        return Y"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XolI2SDucLoc"
      },
      "source": [
        "Creating weights directory and storing all the images and masks in memory to avoid reloading all the time inside the datagenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcbbJd0vZQYe",
        "cellView": "form"
      },
      "source": [
        "#@title Create weights path\n",
        "weights_path = 'weights'\n",
        "if not os.path.exists(weights_path):\n",
        "    os.makedirs(weights_path)\n",
        "weights_path += MODEL_NAME"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYN0WgWAd4S8"
      },
      "source": [
        "Loading the training and validation data..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klJdRHC1cjpr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "df55c95e-7adc-4c57-f64e-c9435c2f5907"
      },
      "source": [
        "#@title Store image and mask in memory\n",
        "TRAIN_IMG_RAW = []\n",
        "TRAIN_IMG_MASK_RAW = []\n",
        "for img_id in tqdm(range(1,25)):\n",
        "  img = normalize(tiff.imread(MAIN_DIR+'mband/{}.tif'.format(str(img_id).zfill(2)))).transpose([1,2,0])\n",
        "  mask = tiff.imread(MAIN_DIR+'gt_mband/{}.tif'.format(str(img_id).zfill(2))).transpose([1,2,0])/255\n",
        "  TRAIN_IMG_RAW.append(img)\n",
        "  TRAIN_IMG_MASK_RAW.append(mask)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████| 24/24 [00:07<00:00,  3.16it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN3RpZIefqA8"
      },
      "source": [
        "Patch generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXlq4o0RpYKW",
        "cellView": "form"
      },
      "source": [
        "#@title function to generate the compressed form of the dataset\n",
        "def get_label(stride = 1,patch_size = PATCH_SZ):\n",
        "  labels = dict()\n",
        "  idx = 0\n",
        "  for i in range(1,25):\n",
        "    img_id = str(i).zfill(2)+'.tif'\n",
        "    img = MAIN_DIR+\"mband/\"+img_id\n",
        "    img = tiff.imread(img).transpose([1,2,0]).shape\n",
        "    w,h = img[0],img[1]\n",
        "    for j in range(0,w-patch_size+1,stride):\n",
        "      for k in range(0,h-patch_size+1,stride):\n",
        "        labels[idx] = (i-1,j,k)\n",
        "        idx+=1\n",
        "  return labels"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tFY2tILva-g"
      },
      "source": [
        "Generating Labels "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW9u-lEavaYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "cf1af734-df89-401a-8509-65ef18ae6f62"
      },
      "source": [
        "#@title Generate the compressed form of the dataset\n",
        "labels = get_label(stride=STRIDE)\n",
        "print(\"Dataset size =\",len(labels))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset size = 177225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKxYPWCsv9-s"
      },
      "source": [
        "Create data generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1y8j2uZv_5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "3ba81702-9b36-45df-ed67-1b8d194fc53a"
      },
      "source": [
        "#@title Split the dataset into train and validation\n",
        "dataset_size = len(labels)\n",
        "indexes = [*range(dataset_size)]\n",
        "np.random.shuffle(indexes)\n",
        "train_idx = indexes[:int(TRAIN_SZ*dataset_size)]\n",
        "val_idx = indexes[int(TRAIN_SZ*dataset_size):]\n",
        "training_generator = DataGenerator(train_idx,labels)\n",
        "validation_generator = DataGenerator(val_idx,labels)\n",
        "print(\"TRAIN size =\",len(train_idx),\"Validation size =\",len(val_idx))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN size = 132918 Validation size = 44307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRkarBCNgbPV"
      },
      "source": [
        "Let's train!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaOUxe1DjFha",
        "cellView": "form"
      },
      "source": [
        "#@title function to get the model\n",
        "def get_model():\n",
        "    return unet_model(N_CLASSES, PATCH_SZ, n_channels=N_BANDS, upconv=UPCONV, class_weights=CLASS_WEIGHTS)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahUprRSQfLpm",
        "cellView": "form"
      },
      "source": [
        "#@title function to train the neural net\n",
        "def train_net():\n",
        "  model = get_model()\n",
        "  if os.path.isfile(weights_path):\n",
        "      model.load_weights(weights_path)\n",
        "  #model_checkpoint = ModelCheckpoint(weights_path, monitor='val_loss', save_weights_only=True, save_best_only=True)\n",
        "  #early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "  #reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5, min_lr=0.00001)\n",
        "  model_checkpoint = ModelCheckpoint('weights/unet_weights--{epoch:02d}-{val_loss:.4f}.hdf5', monitor='val_loss', save_best_only=True)\n",
        "  csv_logger = CSVLogger('log_unet.csv', append=True, separator=';')\n",
        "  tensorboard = TensorBoard(log_dir='./tensorboard_unet/', write_graph=True, write_images=True)\n",
        "  model.fit(training_generator, epochs=N_EPOCHS,\n",
        "            verbose=1,callbacks=[model_checkpoint, csv_logger, tensorboard],\n",
        "            validation_data=validation_generator)\n",
        "  return model"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDKhoLfjguVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "afa4b784-db0c-4db4-bb78-101be1dfbc0c"
      },
      "source": [
        "#@title Start training\n",
        "train_net()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            " 2752/13291 [=====>........................] - ETA: 3:06:14 - loss: 0.1087"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLvZ9swegvkc",
        "cellView": "form"
      },
      "source": [
        "#@title Load the test image and the model\n",
        "model = get_model()\n",
        "model.load_weights(weights_path)\n",
        "img = normalize(tiff.imread(MAIN_DIR+'mband/{}.tif'.format(TEST_IMAGE)).transpose([1,2,0]))   # make channels last"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOmzbT-x0xFe",
        "cellView": "form"
      },
      "source": [
        "#@title Function to predict on the given test image\n",
        "def predict(x, model, patch_sz=160, n_classes=5):\n",
        "    img_height = x.shape[0]\n",
        "    img_width = x.shape[1]\n",
        "    n_channels = x.shape[2]\n",
        "    # make extended img so that it contains integer number of patches\n",
        "    npatches_vertical = math.ceil(img_height / patch_sz)\n",
        "    npatches_horizontal = math.ceil(img_width / patch_sz)\n",
        "    extended_height = patch_sz * npatches_vertical\n",
        "    extended_width = patch_sz * npatches_horizontal\n",
        "    ext_x = np.zeros(shape=(extended_height, extended_width, n_channels), dtype=np.float32)\n",
        "    # fill extended image with mirrors:\n",
        "    ext_x[:img_height, :img_width, :] = x\n",
        "    for i in range(img_height, extended_height):\n",
        "        ext_x[i, :, :] = ext_x[2 * img_height - i - 1, :, :]\n",
        "    for j in range(img_width, extended_width):\n",
        "        ext_x[:, j, :] = ext_x[:, 2 * img_width - j - 1, :]\n",
        "\n",
        "    # now we assemble all patches in one array\n",
        "    patches_list = []\n",
        "    for i in range(0, npatches_vertical):\n",
        "        for j in range(0, npatches_horizontal):\n",
        "            x0, x1 = i * patch_sz, (i + 1) * patch_sz\n",
        "            y0, y1 = j * patch_sz, (j + 1) * patch_sz\n",
        "            patches_list.append(ext_x[x0:x1, y0:y1, :])\n",
        "    # model.predict() needs numpy array rather than a list\n",
        "    patches_array = np.asarray(patches_list)\n",
        "    # predictions:\n",
        "    patches_predict = model.predict(patches_array, batch_size=4)\n",
        "    prediction = np.zeros(shape=(extended_height, extended_width, n_classes), dtype=np.float32)\n",
        "    for k in range(patches_predict.shape[0]):\n",
        "        i = k // npatches_horizontal\n",
        "        j = k % npatches_vertical\n",
        "        x0, x1 = i * patch_sz, (i + 1) * patch_sz\n",
        "        y0, y1 = j * patch_sz, (j + 1) * patch_sz\n",
        "        prediction[x0:x1, y0:y1, :] = patches_predict[k, :, :, :]\n",
        "    return prediction[:img_height, :img_width, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4KgquB21CXf",
        "cellView": "form"
      },
      "source": [
        "#@title Perform prediction\n",
        "prediction = predict(img,model).transpose([2,0,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsFV3M841IHj",
        "cellView": "form"
      },
      "source": [
        "#@title function to generate picture given mask\n",
        "def picture_from_mask(mask, threshold=0):\n",
        "    colors = {\n",
        "        0: [150, 150, 150],  # Buildings\n",
        "        1: [223, 194, 125],  # Roads & Tracks\n",
        "        2: [27, 120, 55],    # Trees\n",
        "        3: [166, 219, 160],  # Crops\n",
        "        4: [116, 173, 209]   # Water\n",
        "    }\n",
        "    z_order = {\n",
        "        1: 3,\n",
        "        2: 4,\n",
        "        3: 0,\n",
        "        4: 1,\n",
        "        5: 2\n",
        "    }\n",
        "    pict = 255*np.ones(shape=(3, mask.shape[1], mask.shape[2]), dtype=np.uint8)\n",
        "    for i in range(1,6):\n",
        "        cl = z_order[i]\n",
        "        for ch in range(3):\n",
        "            pict[ch,:,:][mask[cl,:,:] > threshold] = colors[cl][ch]\n",
        "    return pict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0HNEVgC1lhz",
        "cellView": "form"
      },
      "source": [
        "#@title Generate picture form mask\n",
        "land_map = picture_from_mask(prediction,0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHhNG0hs1zWJ",
        "cellView": "form"
      },
      "source": [
        "#@title Display the land map\n",
        "plt.imshow(land_map.transpose([1,2,0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6apR80ha3-kx",
        "cellView": "form"
      },
      "source": [
        "#@title Diplay the test image\n",
        "img1_8_bit = visualize(MAIN_DIR+'mband/{}.tif'.format(TEST_IMAGE))\n",
        "plt.imshow(img1_8_bit)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}